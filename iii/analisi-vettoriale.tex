\chapter{Analisi vettoriale}
In questo capitolo studieremo come e quando è possibile estendere il teorema fondamentale del calcolo integrale, visto in uno dei precedenti capitoli, in più dimensioni, ovvero quando possiamo passare dall'integrazione di un insieme all'integrazione sulla sua frontiera.
Vedremo i principali risultati che si applicano all'analisi vettoriale in $\R^2$ e $\R^3$, in particolare i teoremi della divergenza (Gauss, Ostrogradskij) e del rotore (Green, Stokes), tutti casi particolari di un teorema di carattere generale noto come \emph{teorema di Stokes}, che riguarda anche le forme differenziali.

\section{Formule di Gauss-Green}
Cominciamo prima dagli integrali in due dimensioni, per poi introdurre gli integrali di superficie e passare anche a quelli in tre dimensioni.
Per studiare questi teoremi dobbiamo innanzitutto introdurre nuove definizioni per gli insiemi, come quelle di \emph{dominio} e di \emph{orientazione}.
\begin{definizione} \label{d:dominio}
	Un insieme $D\subseteq\R^2$ chiuso si dice \emph{dominio} se è la chiusura di un insieme aperto; si dice inoltre \emph{connesso} se l'aperto di cui è chiusura è connesso.

	Un dominio si dice \emph{normale} (e anche regolare) rispetto alla variabile $x$ se, dato un intervallo $[a,b]$ e due funzioni $f,g\colon[a,b]\to\R$ di $\cont{1}\ab$, esso è della forma $\{(x,y)\in\R^2\colon f(x)\leq y\leq g(x) \forall x\in[a,b]\}$; analogamente si definisce per la variabile $y$.

	Infine, un insieme è un \emph{dominio regolare} se è l'unione di domini $D_i$ normali separati, ossia $\mathring{D_j}\cap\mathring{D_k}=\emptyset$ per ogni $j\neq k$.
\end{definizione}
Ogni dominio, essendo chiuso e limitato, è chiaramente anche compatto.

Prendiamo ora la parametrizzazione $\vphi$ di una curva, che sia regolare e definita da $[a,b]$ in $\R^2$: essa è differenziabile in ogni suo punto, dunque esiste il vettore $\vphi'$ per ogni $t\in[a,b]$.
Normalizzando questo vettore otteniamo un versore che indica la direzione tangente alla curva in ogni punto: definiamo dunque il \emph{versore tangente} alla curva $\vphi$ come la funzione $\vphi'/\norm{\vphi'}$, anch'essa da $[a,b]$ a $\R^2$.
A questo punto possiamo definire il \emph{versore normale}, che indicheremo spesso con $\vnu$, come il vettore ottenuto ruotando il versore tangente di $-\pi/2$, ossia
\begin{equation*}
	\vnu(t)=\frac1{\norm{\vphi'(t)}}
	\begin{bmatrix}
		0&1\\-1&0
	\end{bmatrix}
	\begin{bmatrix}
		\phi'_1(t)\\\phi'_2(t)
	\end{bmatrix}
	=\frac1{\norm{\vphi'(t)}}
	\begin{bmatrix}
		\phi'_2(t)\\-\phi'_1(t)
	\end{bmatrix}
\end{equation*}
Chiaramente i due versori sono ortogonali per ogni $t\in[a,b]$.
Se $D$ è un dominio regolare, si può dimostrare che $\partial D$ è l'unione finita di sostegni di curve regolari a tratti: allora possiamo affermare l'esistenza di un versore tangente e normale alla frontiera di un dominio regolare, tranne al più in un numero finito di punti.

Questo ci porta al problema di trovare un'orientazione delle curve, e più precisamente del bordo di un insieme.
Diremo che la frontiera è orientata in senso \emph{positivo} (e scriveremo $+\partial D$) se il versore normale ``punta'' all'esterno del dominio.
Questo indica anche il verso di percorrenza della frontiera: percorrendola in senso positivo il dominio si troverà sempre alla sinistra del versore tangente.

Possiamo dunque dimostrare con gli elementi a disposizione il teorema sviluppato da Gauss e Green.
\begin{teorema}[di Gauss-Green] \label{t:gauss-green}
	Sia $D\subseteq\R^2$ un dominio regolare e $f\colon D\to\R$ una funzione in $\cont{1}(D)$.
	Allora valgono
	\begin{gather}
		\int_D\drp{f}{x}(x,y)\,\dd x\,\dd y=\int_{+\partial D}f(x,y)\,\dd y
		\label{eq:gauss-green-y}\\
		\int_D\drp{f}{y}(x,y)\,\dd x\,\dd y=-\int_{+\partial D}f(x,y)\,\dd x
		\label{eq:gauss-green-x}
	\end{gather}
\end{teorema}
\begin{proof}
	Supponiamo che esista un insieme $U$ tale che $D\subset U$ e che $f\in\cont{1}(U)$.
	Distinguiamo tre casi: $D$ normale rispetto a $y$, normale rispetto a $x$ e regolare.

	Sia $D$ un dominio normale rispetto alla variabile $y$: lo scriviamo allora come $D=\{(x,y)\in\R\times[c,d]\colon \alpha(y)\leq x\leq\beta(y)\}$.
	Suddividiamo il bordo di $D$ nei quattro sottoinsiemi $\gamma_i$ ($i=1,2,3,4$) parametrizzati con
	\begin{gather*}
		\vgamma_1(t)=
		\begin{bmatrix}
			\alpha(t)\\t
		\end{bmatrix}, t\in[d,c],\quad
		\vgamma_2(t)=
		\begin{bmatrix}
			\alpha(c)\\c
		\end{bmatrix}, t\in[c,c],\\
		\vgamma_3(t)=
		\begin{bmatrix}
			\beta(t)\\t
		\end{bmatrix}, t\in[c,d],\quad 
		\vgamma_4(t)=
		\begin{bmatrix}
			\beta(d)\\d
		\end{bmatrix}, t\in[d,d].
	\end{gather*}
	Dimostriamo che entrambi i membri si possono riportare ad una stessa grandezza: cominciamo dal primo, usando il teorema di Fubini ($f\in\cont{1}(D)$ quindi è anche sommabile), per il quale
	\begin{equation}
		\int_D\drp{f}{x}\,\dd x\,\dd y=\int_c^d\int_{\alpha(y)}^{\beta(y)}\drp{f}{x}\,\dd x\,\dd y=\int_c^df(x,y)\bigg|_{x=\alpha(y)}^{x=\beta(y)}\dd y=\int_c^d\Big[f\big(\beta(y),y\big)-f\big(\alpha(y),y\big)\Big]\,\dd y.
	\end{equation}
	Per il secondo membro, invece, scomponiamo l'integrale della forma differenziale sulle quattro curve, ottenendo
	\begin{equation}
		\begin{split}
			\int_{+\partial D}f(x,y)\,\dd y&=\int_d^cf\big(\alpha(t),t\big)\,\dd t+\int_c^cf\big(\alpha(c),c\big)\,\dd t+\int_c^df\big(\beta(t),t\big)\,\dd t+\int_d^df\big(\beta(d),d\big)\,\dd t=\\
			&=\int_c^d\Big[f\big(\beta(t),t\big)-f\big(\alpha(t),t\big)\Big]\,\dd t
		\end{split}
	\end{equation}
	che è lo stesso risultato precedente.

	Sia ora $D$ normale rispetto a $x$: rappresentiamolo come $\{(x,y)\in[a,b]\times\R\colon\delta(x)\leq y\leq\eta(y)\}$.
	Per $(x,y)\in D$, consideriamo la curva $\gamma\subset D$ parametrizzata con la funzione
	\begin{equation*}
		\vgamma(t)=
		\begin{cases}
			\big(t,\delta(t)\big) &t\in[a,x]\\
			(x,t) &t\in[\delta(x),y]
		\end{cases}
	\end{equation*}
	che è regolare a tratti, e collega $\big(a,\delta(a)\big)$ ad un generico punto in $D$.
	Definiamo
	\begin{equation*}
		G(x,y)\defeq\int_{\gamma}f(x,y)\,\dd x\,\dd y:
	\end{equation*}
	risulta spezzando l'integrale nelle due curve che
	\begin{equation}
		G(x,y)=\int_a^xf\big(t,\delta(t)\big)\,\dd t+\int_{\delta(x)}^yf(x,t)\,\dd t.
	\end{equation}
	Calcoliamone le derivate parziali: troviamo
	\begin{equation}
		\drp{G}{x}(x,y)=f\big(x,\delta(x)\big)\delta'(x)+\int_{\delta(x)}^y\drp{f}{x}(x,t)\,\dd t-f\big(x,\delta(x)\delta'(t)=\int_{\delta(x)}^y\drp{f}{x}(x,y)\,\dd t.
	\end{equation}
	La derivata rispetto a $y$ invece è semplicemente $\drp{G}{y}(x,y)=f(x,y)$, dato che il primo dei due integrali addendi non dipende da $y$ e il secondo è una funzione integrale con estremo inferiore costante in $y$.
	Prendiamo la forma differenziale $\dd G=\drp{G}{x}\,\dd x+\drp{G}{y}\,\dd y$: essa è ovviamente esatta.
	Inoltre $\partial D$ è chiusa e regolare a tratti, dunque l'integrale di $\dd G$ lungo di essa è nullo: allora
	\begin{equation}
		\int_{+\partial D}\drp{G}{x}\,\dd x=-\int_{+\partial D}\drp{G}{y}\,\dd y.
		\label{eq:dim-gauss-green-forma-esatta}
	\end{equation}
	Calcoliamo il primo membro: scomponendo nei quattro tratti regolari di $\partial D$ abbiamo
	\begin{equation}
		\begin{split}
			\int_{+\partial D}\drp{G}{x}\,\dd x&=\int_a^b\drp{G}{x}(x,y)\,\dd x+\int_b^b\drp{G}{x}(x,y)\dd x+\int_b^a\drp{G}{x}(x,y)\,\dd x+\int_a^a\drp{G}{x}(x,y)\,\dd x=\\
			&=\int_a^b\int_{\delta(x)}^{\eta(x)}\drp{f}{x}(x,t)\,\dd t\,\dd x+\int_b^a\int_{\delta(x)}^{\eta(x)}\drp{f}{x}(x,t)\,\dd t\,\dd x=\\
			&=-\int_a^b\int_{\delta(x)}^{\eta(x)}\drp{f}{x}(x,t)\,\dd t\,\dd x. (?)
		\end{split}
	\end{equation}
	Sostituendo infine quanto ricavato precedentemente per le derivate parziali di $G$ la \eqref{eq:dim-gauss-green-forma-esatta} diventa
	\begin{equation}
		-\int_a^b\int_{\delta(x)}^{\eta(x)}\drp{f}{x}(x,t)\,\dd t\,\dd x=-\int_{+\partial D}f(x,y)\,\dd y
	\end{equation}
	cioè applicando il teorema di Fubini ``al contrario'', cioè passando all'integrale di area,
	\begin{equation}
		\int_D\drp{f}{x}(x,y)\,\dd x\,\dd y=\int_{+\partial D}f(x,y)\,\dd y.
	\end{equation}

	Se infine $D$ è un dominio regolare, ma non è normale rispetto ad una delle due variabili, possiamo comunque scomporlo in vari domini normali $D_i$ separati.
	Per ciascuno di essi vale quanto detto precedentemente, perciò
	\begin{equation}
		\int_D\drp{f}{x}(x,y)\,\dd x\,\dd y=\sum_i\int_{D_i}\drp{f}{x}(x,y)\,\dd x\,\dd y=\sum_i\int_{+\partial D_i}f\,\dd y.
	\end{equation}
	Poich\'e le frontiere dei vari $D_i$ sono in comune, in ciascun addendo di quest'ultima somma ciascuna porzione di frontiera che si trova tra due $D_i$ viene percorsa, integrando, una volta in un senso e una volta nell'altro.
	Chiaramente ciascuna delle due volte la funzione integranda è la stessa, quindi i due integrali hanno segno opposto e si annullano.
	Rimane nel conto quindi solo le parti delle frontiere che sono esterni, ossia proprio $\partial D$, quindi
	\begin{equation}
		\sum_i\int_{+\partial D_i}f\,\dd y=\int_{+\partial D}f\,\dd y.\qedhere
	\end{equation}
\end{proof}

\begin{teorema}[della divergenza] \label{t:divergenza-R2}
	Sia $D\subset\R^2$ un dominio regolare e $\vec F\colon D\to\R^2$ un campo vettoriale di classe $\cont{1}(D)$.
	Se $\vnu(x,y)$ è il versore normale al bordo di $D$ uscente da esso, allora
	\begin{equation}
		\int_D\div\vec F\,\dd x\,\dd y=\int_{\partial D}\scalar{\vec F}{\vnu}\,\dd s
		\label{eq:divergenza-R2}
	\end{equation}
\end{teorema}
\begin{proof}
	Parametrizziamo $\partial D$, che è regolare a tratti, con una funzione $\cont{1}$ a tratti $\vphi(t)=\big(x(t),y(t)\big)$, con $t\in[a,b]$.
	Il versore normale con questa scelta assume quindi la forma
	\begin{equation*}
		\vnu(t)=\frac1{\sqrt{x'^2(t)+y'^2(t)}}
		\begin{bmatrix}
			y'(t)\\-x'(t)
		\end{bmatrix}
	\end{equation*}
	L'integrale curvilineo al secondo membro della \eqref{eq:divergenza-R2} è dunque
	\begin{equation}
		\begin{split}
			\int_{\partial D}\scalar{\vec F}{\vnu}\,\dd s&=\int_a^b\bigg(\frac{F_1\big(\vphi(t)\big)y'(t)}{\sqrt{x'^2(t)+y'^2(t)}}-\frac{F_2\big(\vphi(t)\big)x'(t)}{\sqrt{x'^2(t)+y'^2(t)}}\bigg)\sqrt{x'^2(t)+y'^2(t)}\,\dd t=\\
			&=\int_a^b\big[(F_1\big(\vphi(t)\big)y'(t)-F_2\big(\vphi(t)\big)x'(t)\big]\,\dd t=\\
			&=\int_{\partial D}\big[F_2\big(\vphi(t)\big)\,\dd y-F_2\big(\vphi(t)\big)\,\dd x\big]
		\end{split}
	\end{equation}
	che per il teorema \ref{t:gauss-green} è uguale a
	\begin{equation}
		\int_D\drp{F_1}{x}(x,y)\,\dd x\,\dd y+\int_D\drp{F_2}{y}(x,y)\,\dd x\,\dd y=\int_D\div\vec F(x,y)\,\dd x\,\dd y.\qedhere
	\end{equation}
\end{proof}
\begin{teorema}[del rotore, di Stokes] \label{t:rotore-R2}
	Sia $\vec F\colon D\to\R^2$ un campo vettoriale di classe $\cont{1}(D)$ e $D\subset\R^2$ un dominio regolare.
	Allora
	\begin{equation}
		\int_{+\partial D}\big(F_1(x,y)\,\dd x+F_2(x,y)\,\dd y\big)=\int_D\bigg(\drp{F_2}{x}(x,y)-\drp{F_1}{y}(x,y)\bigg)\,\dd x\,\dd y.
		\label{eq:rotore-R2}
	\end{equation}
\end{teorema}
\begin{proof}
	La dimostrazione è immediata se applichiamo il teorema della divergenza \ref{t:divergenza-R2} al campo $\vec F(x,y)=\big(F_2(x,y),-F_1(x,y)\big)$, per il quale
	\begin{equation}
		\int_{+\partial D}\scalar{\vec F}{\vnu}\,\dd s=\int_{+\partial D}(F_2(x,y)\,\dd y+F_1(x,y)\,\dd x)=\int_D\drp{F_2}{x}(x,y)\,\dd x\,\dd y-\int_D\drp{F_1}{x}(x,y)\,\dd x\,\dd y
	\end{equation}
	da cui la tesi.
\end{proof}
Grazie a questi teoremi appena dimostrati possiamo portare in più dimensioni la formula di integrazione per parti: si ha, dati $f,g\colon D\to\R$ e $D\subset\R^2$ dominio regolare,
\begin{gather}
	\int_D f(x,y)\drp{g}{x}(x,y)\,\dd x\,\dd y=\int_{+\partial D}f(x,y)g(x,y)\,\dd y-\int_D\drp{f}{x}(x,y)g(x,y)\,\dd x\,\dd y\\
	\int_D f(x,y)\drp{g}{y}(x,y)\,\dd x\,\dd y=-\int_{+\partial D}f(x,y)g(x,y)\,\dd x-\int_D\drp{f}{y}(x,y)g(x,y)\,\dd x\,\dd y
\end{gather}
Per dimostrarlo è sufficiente applicare il teorema di Gauss-Green \ref{t:gauss-green} alla funzione $fg$.

Dato un versore $\vec w$ di $\R^2$, possiamo anche dare una formulazione del \ref{t:gauss-green} per le derivate direzionali: assumendo sempre $D$ dominio regolare,
\begin{equation}
	\int_DD_{\vec w}f\,\dd x\,\dd y=\int_{\partial D}f\scalar{\vec w}{\vnu}\,\dd s.
\end{equation}
Infatti, applicando il teorema della divergenza \ref{t:divergenza-R2} al campo $f\vec w=(fw_1,fw_2)$, si ottiene
\begin{equation}
	\begin{split}
		\int_D\div(f\vec w)\,\dd x\,\dd y&=\int_D\bigg[\drp{fw_1}{x}(x,y)+\drp{fw_2}{y}(x,y)\bigg]\,\dd x\,\dd y=\\
		&=\int_D\bigg[w_1\drp{f}{x}(x,y)+w_2\drp{f}{y}(x,y)\bigg]\,\dd x\,\dd y=\\
		&=\int_D\scalar{\vec w}{\grad f}\,\dd x\,\dd y=\int_DD_{\vec w}f(x,y)\,\dd x\,\dd y
	\end{split}
\end{equation}
ma allo stesso tempo
\begin{equation}
	\int_D\div(f\vec w)\,\dd x\,\dd y=\int_{\partial D}\scalar{(f\vec w)}{\vnu}\,\dd s=\int_{\partial D}f(\scalar{\vec w}{\vnu})\,\dd s.
\end{equation}

Un'ultima applicazione di questi risultati è il calcolo dell'area di $D$: notiamo che in $\int_D\dd x,\dd y$ possiamo prendere l'integranda come derivata parziale di $f(x,y)=x$ rispetto a $x$ (che quindi vale 1), perciò per il teorema di Gauss-Green \ref{t:gauss-green} abbiamo
\begin{equation}
	\mu(D)=\int_D\dd x\,\dd y=\int_{+\partial D}x\,\dd y\text{ o anche }-\int_{+\partial D}y\,\dd x.
\end{equation}
Possiamo quindi prendere una combinazione arbitraria delle due, in cui presi $\alpha$ e $\beta$ tali che $\alpha+\beta=1$ si ha
\begin{equation}
	\int_{+\partial D}(\alpha x\,\dd y-\beta y\,\dd x)=(\alpha+\beta)\int_D\dd x\,\dd y=\int_D\dd x\,\dd y=\mu(D)
\end{equation}

\section{Integrali di superficie}
Per continuare lo studio dei teoremi analoghi a quelli appena visti ma in $\R^3$, dobbiamo prima introdurre la teoria delle superfici e degli integrali su di esse.
Vedremo, data una superficie immersa in $\R^3$, come possiamo parametrizzarla con una mappa $\vphi\colon E\to\R^2$.

Cominciamo introducendo il prodotto vettoriale tra due vettori di $\R^3$.
\begin{definizione} \label{d:prodotto-vettoriale}
	Siano $\vec u,\vec v\in\R^3$: si definisce \emph{prodotto vettoriale} tra di essi il vettore
	\begin{equation}
		\vec u\times\vec v=
		\begin{vmatrix}
			u_2& v_2\\u_3&v_3
		\end{vmatrix}\ii+
		\begin{vmatrix}
			u_3&v_3\\u_1&v_1
		\end{vmatrix}\jj+
		\begin{vmatrix}
			u_1&v_1\\u_2&v_2
		\end{vmatrix}\kk
		\label{eq:prodotto-vettoriale}
	\end{equation}
	dove $\{\ii,\jj,\kk\}$ è la base canonica di $\R^3$.
\end{definizione}
Notiamo che i tre determinanti sono i minori della matrice ottenuta affiancando $\vec u$ e $\vec v$: in particolare, il coefficiente dell'$i$-esimo elemento della base è il minore di tale matrice eliminando la $i$-esima riga.
Possiamo quindi scrivere in forma più compatta, anche se formalmente sbagliata, una formula mnemonica per calcolare il prodotto vettoriale tramite il falso determinante
\begin{equation*}
	\vec u\times\vec v=
	\begin{vmatrix}
		\ii& u_1& v_1\\
		\jj& u_2& v_2\\
		\kk& u_3& v_3
	\end{vmatrix}.
\end{equation*}
Il prodotto vettoriale gode delle seguenti proprietà, facilmente dimostrabili dalla proprietà dei determinanti:
\begin{itemize}
	\item è lineare nelle due variabili: $(a\vec v)\times(b\vec u)=ab(\vec v\times\vec u)$, e $(a\vec v+b\vec u)\times\vec w=a\vec v\times\vec w+b\vec u\times\vec w$;
	\item è nullo se i due vettori sono linearmente dipendenti;
	\item se $\vec v\times\vec w\neq\vec 0$, allora $\vec v\times\vec w\perp\gen{\{\vec v,\vec w\}}$, ossia il prodotto vettoriale è ortogonale al piano individuato dai due vettori, inoltre $\{\vec v,\vec w,\vec v\times\vec w\}$ è una base destrorsa di $\R^3$;
	\item $\ii\times\jj=\kk$, $\jj\times\kk=\ii$ e $\kk\times\ii=\jj$ (permutazioni cicliche);
	\item $\norm{\vec v\times\vec u}=\norm{\vec v}\norm{\vec u}\sin\alpha$, dove $\alpha\in[0,\pi]$ è l'angolo compreso tra i due vettori nel piano, cioè
		\begin{equation}
			\norm{\vec v\times\vec u}=\norm{\vec v}\norm{\vec u}\sin\bigg(\arccos\frac{\scalar{\vec v}{\vec u}}{\norm{\vec v}\norm{\vec u}}\bigg).
		\end{equation}
	\item il prodotto è indipendente dalla scelta del sistema di coordinate.
\end{itemize}
Il prodotto vettoriale indica anche come si trasformano le superfici tramite delle funzioni.
Prendiamo ad esempio una funzione $\vphi\colon\R^2\to\R^3$ che sia lineare: la sua immagine in $\R^3$ è quindi proprio un piano.
La sua matrice jacobiana è quindi costante, e può anche essere vista come la matrice associata all'applicazione lineare che è $\vphi$, ossia moltiplicando un vettore del dominio di $\vphi$ per $\jac{\vphi}$ otteniamo proprio l'immagine di tale vettore attraverso la funzione.
Chiamiamo ora $\drp{\vphi}{x}$ e $\drp{\vphi}{y}$ le due colonne della jacobiana (sono rispettivamente la colonna delle derivate rispetto ad $x$ e ad $y$).
Poich\'e $\ii$ e $\jj$ sono linearmente indipendenti, anche $\vphi(\ii)=\drp{\vphi}{x}$ e $\vphi(\jj)=\drp{\vphi}{y}$ lo sono, quindi la jacobiana ha rango massimo (pari a 2).
Allora per le proprietà viste precedentemente il loro prodotto vettoriale non è nullo, quindi $\gen{\{\drp{\vphi}{x},\drp{\vphi}{y}\}}$ è un piano in $\R^3$, che è anche il sostegno di $\vphi$.

Abbiamo visto che gli integrali di linea sono del tipo $\int_\gamma f\,\dd s$, dove $\dd s$ è la misura (infinitesima) della linea lungo su cui vogliamo integrare.
Essi sono equivalenti a $\int_\gamma f\big(\vgamma(t)\big)\norm{\vgamma'(t)}\,\dd t$, in cui $\vgamma(t)$ è una parametrizzazione di $\gamma$.
Gli integrali di superficie si scrivono in maniera analoga come $\int_S f\,\dd\sigma$, dove questa volta chiaramente $\dd\sigma$ è la misura di superficie di $S$.
Vogliamo anche in questo caso trovare un modo di esprimere questa misura superficiale in termini di una parametrizzazione scelta per $S$, come per gli integrali di linea, e ci viene in aiuto il prodotto vettoriale.
Infatti partiamo dal rettangolo $T$ esteso dai vettori $a\ii$ e $b\jj$ in $\R^2$, e $P$ la sua immagine attraverso la funzione $\vphi\colon\R^2\to\R^3$.
Ovviamente $\mu(T)=\abs{ab}$.
Per come abbiamo visto finora, le immagini dei due vettori che individuano $T$ sono $a\drp{\vphi}{x}$ e $b\drp{\vphi}{y}$, quindi finch\'e $\vphi$ è lineare abbiamo
\begin{equation*}
	\mu(P)=\norm{a\drp{\vphi}{x}\times b\drp{\vphi}{y}}=\abs{ab}\norm{\drp{\vphi}{x}\times\drp{\vphi}{y}}=\mu(T)\norm{\drp{\vphi}{x}\times\drp{\vphi}{y}}.
\end{equation*}
Preso un qualsiasi insieme misurabile, il ragionamento appena fatto si applica anche ad esso, e non solo ai rettangoli.
Quando abbiamo detto finora ovviamente non si applica globalmente a funzioni qualunque, ma dato che ci interessa calcolare la misura di superficie infinitesima possiamo sfruttare uno sviluppo al primo ordine (quindi lineare, o affine) della funzione di parametrizzazione, e ottenere gli stessi risultati.
Abbiamo trovato dunque che, data $f\colon A\to\R$, e data $\vpsi\colon D\to\R^3$ come parametrizazione di $A$, l'integrale di superficie è
\begin{equation}
	\int_Af\,\dd\sigma=\int_Df\big(\vpsi(u,v)\big)\norm{\drp{\vpsi}{u}(u,v)\times\drp{\vpsi}{v}(x,y)}\,\dd u\,\dd v.
\end{equation}

Si può vedere che l'integrale $\int_Sf\,\dd\sigma$ non dipende dalla parametrizzazione scelta per $S$, ma dipende soltanto (ovviamente) dal suo sostegno, che è $S$.
Diciamo infine che un sottoinsieme $E\subseteq S$ è $\sigma$-misurabile, dove $\sigma$ è la misura di superficie su $S$, se la sua funzione caratteristica è integrabile su $S$, e vale
\begin{equation}
	\sigma(E)=\int_S\chi_E\,\dd\sigma
\end{equation}
Per trovare l'area di $S$ si integra quindi la funzione caratteristica di tutto $S$.
Valgono ovviamente anche in questo caso le solite proprietà di integrazione, in particolare
\begin{equation}
	\abs{\int_Sf\,\dd\sigma}\leq\int_S\abs{f}\dd\sigma\leq\sup_S\abs{f}\sigma(S)
\end{equation}
dove $\sigma(S)$ è l'area di $S$.

\section{Teorema della divergenza e del rotore in $\R^3$}
Cominciamo adattando quanto detto sui domini e l'orientazione di curve anche a insiemi in $\R^3$.
\begin{definizione} \label{d:dominio-R3}
	Un insieme $D\subset\R^3$ si dice:
	\begin{itemize}
		\item \emph{dominio normale} rispetto alla coppia di variabili $x,y$ se si può scrivere come $\{(x,y,z)\in\R^3\colon(x,y)\in E, \alpha(x,y)\leq z\leq\beta(x,y)\}$, dove $E\subset\R^2$ è un dominio regolare, $\alpha,\beta\colon E\to\R$ sono di classe $\cont{1}(E)$ e $\alpha(x,y)\leq\beta(x,y)\forall(x,y)\in E$;
		\item \emph{dominio regolare} se è unione di un numero finito di domini $\{D_i\}_{i=1}^n$, $n\in\N$, ciascuno normale rispetto ad una coppia di variabili (non necessariamente la stessa per tutti), e tali per cui $\mathring{D_i}\cap\mathring{D_j}=\emptyset$ per $i\neq j$.
	\end{itemize}
\end{definizione}
\begin{osservazione}
	Se $T\subset\R^3$ è un dominio regolare, allora è connesso e compatto, dunque la sua frontiera ha misura nulla.
	Inoltre esiste un numero finito di superfici regolari $\{S_i\}_{i=1}^n$, $n\in\N$, ciascuna parametrizzabile con $\vphi_i\colon D_i\to\R^3$ per $i=1,\dots,n$ (tali quindi che $\vphi_i(D_i)=S_i$), per le quali\footnote{Con \emph{superficie regolare} intendiamo un concetto analogo a quello di curva regolare: se nel secondo caso  chiediamo che la derivata della parametrizzazione della curva non sia mai un vettore nullo, per le superfici chiediamo che la jacobiana della parametrizzazione abbia sempre rango massimo (ma in realtà si può vedere che sono la stessa condizione).}
	\begin{equation*}
		\partial T=\bigcup_{i=1}^n\vphi_i(D_i)
	\end{equation*}
	con $\vphi_i(\mathring{D_i})\cap\vphi_j(\mathring{D_j})=\emptyset$ per $i\neq j$.
\end{osservazione}
Possiamo estendere il concetto di integrale di superficie anche a queste frontiere, dato che sono unione numerabile di insiemi disgiunti, a meno di insiemi di misura nulla: infatti l'intersezione di due superfici di cui è composta la frontiera è al più una curva, che ha misura (superficiale) nulla, quindi non influisce sull'integrale.
Se le superfici hanno in comune solo la frontiera, allora
\begin{equation*}
	\int_{\partial T}f\,\dd\sigma=\sum_{i=1}^n\int_{S_i}f\,\dd\sigma
\end{equation*}
usando la notazione della predecente osservazione.

Vediamo ora come è possibile assegnare un'orientazione anche alle superfici.
Se $\vphi\colon D\subset\R^2\to\R^3$ è la parametrizzazione di una superficie regolare $S$ immersa in $R^3$, cioè per cui $\vphi(D)=S$, chiamiamo $S_o\defeq\vphi(\mathring{D})$ che è tale per cui la restrizione $\vphi\colon\mathring{D}\to S_o$ sia biunivoca.\footnote{Nonostante la scrittura possa suggerirlo, non è vero che $S_o=\mathring{S}$, infatti dato che $S$ è una superficie regolare in $\R^3$ essa coincide con la sua frontiera, perciò $\mathring{S}=\emptyset$.}
Per ogni $\vec x\in S_o$ possiamo associare un versore normale $\vnu(\vec x)$, definito come
\begin{equation}
	\vnu(\vec x)=\frac{\drp{\vphi}{u}(u,v)\times\drp{\vphi}{v}(u,v)}{\norm{\drp{\vphi}{u}(u,v)\times\drp{\vphi}{v}(u,v)}}
\end{equation}
con $(u,v)=\vphi^{-1}(\vec x)$.
La mappa $\vnu\colon S_o\to\R^3$ è continua, e dipende ``in modo continuo'' dall'inclinazione della superficie.
\begin{definizione} \label{d:superficie-orientabile}
	Sia $S\subset\R^3$ una superficie regolare parametrizzata da $\vphi\colon D\to\R^3$, e chiamiamo $S_o=\vphi(\mathring{D})$.
	La superficie $S$ si dice orientabile se il campo del versore normale $\vnu$ si può estendere con continuità da $S_o$ a tutta $S$.
\end{definizione}
Possiamo quindi anche trovare una \emph{riparametrizzazione} di una superficie: prese le parametrizzazioni $\vphi\colon D\to\R^3$ e $\vpsi\colon T\to\R^3$, esse sono equivalenti tramite $\vtau\colon D\to T$ (una riparametrizzazione) se $S_o=\vphi(\mathring{D})=\vpsi(\mathring{T})$ e se ovviamente dato $\vec x\in S_o$ si ha $\vec x=\vphi(\vec u)=\vpsi(\vec v)$, per $\vec u\in D$ e $\vec v\in T$.
Il versore normale nella nuova parametrizzazione è dunque
\begin{equation}
	\vnu_{\vpsi}\big(\vpsi(\vec u)\big)=\sgn\big(\det\jac\vtau(\vec u)\big)\vnu_{\vphi}\big(\vphi(\vec v)\big)
\end{equation}
Per la continuità il segno può essere o 1 o $-1$ in tutto il dominio.
Si indica $\vphi\sim\vpsi$ se esse hanno lo stesso sostegno con una riparametrizzazione, e ulteriormente $\vphi\overset{o}{\sim}\vpsi$ se sono anche equiorientate, cioè se il versore normale coincide.

\begin{osservazione} \label{o:superfici-cartesiane}
	Il grafico di una funzione $f\colon D\subset\R^2\to\R$ (detto anche \emph{superficie cartesiana}) è sempre orientabile: esso può essere parametrizzato con $\vphi=\big(u,v,f(u,v)\big)^t$, la cui matrice jacobiana è
	\begin{equation*}
		J\vphi(u,v)=
		\begin{bmatrix}
			1&0\\
			0&1\\
			\drp{f}{u}(u,v)&\drp{f}{v}(u,v)
		\end{bmatrix},
	\end{equation*}
	che ha sempre rango massimo, qualsiasi sia la funzione $f$, perch\'e il minore dato dalle prime due righe è sempre 1.
	Un vettore normale alla superficie assume una semplice forma, che è
	\begin{equation*}
		\vnu\big(\vphi(u,v)\big)=\drp{\vphi}{u}(u,v)\times\drp{\vphi}{v}(u,v)=\bigg(-\drp{f}{u}(u,v),\drp{f}{v}(u,v),1\bigg)^t.
	\end{equation*}
\end{osservazione}
Un'altra superficie facile da orientare è una superficie sferica: essa ammette in particolare sempre due orientazioni, una uscente e una entrante, facili da visualizzare.
Data la sua equazione $x^2+y^2+z^2=r^2$, inoltre, il versore normale è sempre di tipo radiale, ossia $\vnu(x,y,z)=\pm\frac1{r^2}(x,y,z)^t$.

Una classica superficie non orientabile è invece il \emph{nastro di M\"obius}: per parametrizzarlo si dovrebbe tagliare il nastro in un punto, in cui il versore normale ``salta'' da una faccia all'altra.
Ma allora è evidente che $\vnu$, pur essendo ben definito in tutto $S_o$, non può essere esteso con continuità anche sul resto di $S$, perch\'e proprio nel punto del taglio si ha necessariamente una discontinuità.
In realtà, non sarebbe corretto dire che $\vnu$ salta da una faccia all'altra\dots perch\'e il nastro di M\"obius ha soltanto una faccia.
Sebbene localmente si possano individuare due facce (e quindi due versori normali opposti), globalmente in tutto il nastro la faccia è soltanto una!

\begin{definizione} \label{d:superfici-con-bordo}
	Sia $\vphi\colon D\to\R^3$ la parametrizzazione di una superficie $S$ regolare, con $D$ dominio regolare connesso: essa si dice \emph{superficie con bordo} se $\vphi$ è iniettiva su $D$ e se si può individuare un insieme $E\supset D$ aperto e una funzione $\tilde{\vphi}\colon E\to\R^3$, di classe $\cont{1}(E)$, tale che la sua restrizione in $D$ coincida con $\vphi$.
\end{definizione}
Per queste superfici definiamo allora $\partial S\defeq\vphi(\partial D)$.
Il bordo di $D$, che è un dominio regolare, si può esprimere sempre come unione di curve semplici, regolari e tutte disgiunte.
Se dunque $\vgamma$ è una parametrizzazione di $+\partial D$ (cioè il versore normale al bordo di $D$ è esterno all'insieme), allora componendo la parametrizzazione della superficie, $\vphi$, con essa si ottiene $\vphi\circ\vgamma$ la quale è appunto una parametrizzazione del bordo di $S$, ed è una curva in $\R^3$.
Anche in questo caso si scrive $+\partial S$, ossia $\partial S$ diventa orientata in senso antiorario (e si dice che l'orientazione è indotta da $\partial D$).

